{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', transform=transform, download=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST('./data', transform=transform, download=True, train=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def one_hot(x, max_x):\n",
    "    return torch.eye(max_x+1)[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([3, 4, 5])\n",
    "y = torch.tensor([\n",
    "    [0, 0, 0, 1, 0, 0, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, dataloader, loss_fn=nn.MSELoss(), flatten=True,\n",
    "                  conditional=False):\n",
    "    losses = []\n",
    "    for batch, labels in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        if flatten:\n",
    "            batch = batch.view(batch.size(0), 28*28)\n",
    "        if conditional:\n",
    "            loss = loss_fn(batch, model(batch, labels))\n",
    "        else:\n",
    "            loss = loss_fn(batch, model(batch))\n",
    "        \n",
    "        losses.append(loss)\n",
    "    \n",
    "    return (sum(losses)/len(losses)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_visual_progress(model, test_dataloader, row=5, flatten=True,\n",
    "                         vae=False, conditional=False, title=None):\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    \n",
    "    iter(test_dataloader)\n",
    "    \n",
    "    image_rows = []\n",
    "    \n",
    "    for idx, (batch, label) in enumerate(test_dataloader):\n",
    "        if row == idx:\n",
    "            break\n",
    "        \n",
    "        batch = batch.to(device)\n",
    "        if flatten:\n",
    "            batch = batch.view(batch.size(0), 28*28)\n",
    "        \n",
    "        if not conditional:\n",
    "            images = model(batch).detach().cpu().numpy().reshape(batch.size(0), 28, 28)\n",
    "        else:\n",
    "            images = model(batch, label).detach().cpu().numpy().reshape(batch.size(0), 28, 28)\n",
    "        \n",
    "        image_idxs = [list(label.numpy()).index(x) for x in range(10)]\n",
    "        combined_images = np.concatenate([images[x].reshape(28, 28) for x in image_idxs], 1)\n",
    "        \n",
    "        image_rows.append(combined_images)\n",
    "        plt.imshow(np.concatenate(image_rows))\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(losses, autoencoder, dataloader, flatten=True, vae=False,\n",
    "             conditional=False):\n",
    "    if vae and conditional:\n",
    "        model = lambda x, y: autoencoder(x, y)[0]\n",
    "    elif vae:\n",
    "        model = lambda x: autoencoder(x)[0]\n",
    "    else:\n",
    "        model = autoencoder\n",
    "    \n",
    "    loss = calculate_loss(model, dataloader, flatten=flatten, conditional=conditional)\n",
    "#     show_visual_progress(model, test_dataloader, flatten=flatten, vae=vae, \n",
    "#                          conditional=conditional)\n",
    "    print(loss)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, dataloader, test_dataloader, epochs=5, flatten=False,\n",
    "          loss_fn=nn.MSELoss()):\n",
    "    optim = torch.optim.Adam(net.parameters())\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    for i in range(epochs):\n",
    "        for batch, labels in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            if flatten:\n",
    "                batch = batch.view(batch.size(0), 28*28)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            loss = loss_fn(batch, net(batch))\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        evaluate(validation_losses, net, test_dataloader, flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nparameters(model):\n",
    "    def times(shape):\n",
    "        parameters = 1\n",
    "        for layer in list(shape):\n",
    "            parameters *= layer\n",
    "        \n",
    "        return parameters\n",
    "    layer_params = [times(x.size()) for x in list(model.parameters())]\n",
    "    \n",
    "    return sum(layer_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden=10):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, hidden))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_size))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10473746061325073\n",
      "0.09068146347999573\n",
      "0.08406133204698563\n",
      "0.0804152637720108\n",
      "0.07708583027124405\n",
      "0.07402276992797852\n",
      "0.07214543223381042\n",
      "0.0711098313331604\n",
      "0.06941736489534378\n",
      "0.0687880888581276\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder(28*28).to(device)\n",
    "train(autoencoder, train_dataloader, test_dataloader, epochs=10, flatten=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, (3, 3), stride=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(16, 8, (3, 3), stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=1))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, (3, 3), stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, (5, 5), stride=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),\n",
    "            nn.Tanh())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.decoder(self.encoder(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20470894873142242\n",
      "0.15844248235225677\n",
      "0.14456099271774292\n",
      "0.1364603340625763\n",
      "0.12973830103874207\n",
      "0.12505628168582916\n",
      "0.12228311598300934\n",
      "0.11984138190746307\n",
      "0.11817315220832825\n",
      "0.1166527271270752\n",
      "0.11594672501087189\n",
      "0.11423417925834656\n",
      "0.11302926391363144\n",
      "0.11225937306880951\n",
      "0.11140009760856628\n",
      "0.11065704375505447\n",
      "0.10954054445028305\n",
      "0.10923619568347931\n",
      "0.10844851285219193\n",
      "0.10860192030668259\n"
     ]
    }
   ],
   "source": [
    "cnn_ae = CNNAutoencoder().to(device)\n",
    "train(cnn_ae, train_dataloader, test_dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc21 = nn.Linear(512, 10)\n",
    "        self.fc22 = nn.Linear(512, 10)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(10, 512)\n",
    "        self.fc4 = nn.Linear(512, input_size)\n",
    "    \n",
    "    def encoder(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        return self.fc21(x), self.fc22(x)\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        z = self.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(z))\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.rand_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x = self.decoder(z)\n",
    "        \n",
    "        return x, mu, logvar        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_fn(x, recon_x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    \n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5*torch.sum(1+logvar-mu.pow(2)-logvar.exp())\n",
    "    \n",
    "    return BCE+KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(net, dataloader, test_dataloader, flatten=True, epochs=10):\n",
    "    validation_losses = []\n",
    "    optim = torch.optim.Adam(net.parameters())\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        for batch in dataloader:\n",
    "            batch = batch[0].to(device)\n",
    "            if flatten:\n",
    "                batch = batch.view(batch.size(0), 28*28)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            x, mu, logvar = net(batch)\n",
    "            loss = vae_loss_fn(batch, x, mu, logvar)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        \n",
    "        evaluate(validation_losses, net, test_dataloader, vae=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9095661044120789\n",
      "0.8928028345108032\n",
      "0.8846414089202881\n",
      "0.8809676170349121\n",
      "0.8797862529754639\n",
      "0.8788581490516663\n",
      "0.8773050308227539\n",
      "0.8755577206611633\n",
      "0.8746713399887085\n",
      "0.8739920258522034\n"
     ]
    }
   ],
   "source": [
    "vae = VAE(28*28).to(device)\n",
    "train_vae(vae, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'VAE' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-fdcc418f6d5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'VAE' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "vae[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
